\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath, amsfonts, amsthm}
\usepackage{todonotes}
\usepackage{comment} 

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\newtheorem{theorem}{Theorem}
\numberwithin{theorem}{subsection}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\newcommand{\R}{\mathbb{R}}
\newcommand{\todog}{\todo[inline, color=green!40]}

\title{A User's Guide to Calculus in $\mathbb{R}^n$}
\author{Shimal Harichurn}

\begin{document}
	\maketitle
	\begin{abstract}
		\begin{center}
			This is a set of notes that I'm compiling on my way to understanding and learning Calculus in $\mathbb{R}^n$. Think of this as a user's guide to Calculus in $\mathbb{R}^n$.
		\end{center}
	\end{abstract}
	
	\section{Introduction}
		
	Calculus is hard. I'll be honest I understand more about General Topology (even Algebraic Topology) than I do basic Calculus at this point in time. Heck I think I even understand (truly) basic Category Theory better than basic Calculus at this point in time. \\
		
	The reason for this, is I think the folllowing; Topology and Algebra are fields (no pun intended) of mathematics that are very structural in nature to me. You take a set, put a topology on it and voila you have a topological space. \\
			
	Calculus is different, there's no real inherent structure (to me at this point in time).
	\newpage
	\section{Differentiation in $\mathbb{R}^1$}
	Let's dive head on into it.
	\subsection{Prerequisites}
	To define the derivative in $\mathbb{R}^1$ we need to recap the definition(s) of a limit from metric space theory. The reason for this is that we need the notion of a limit to even define the derivative rigorously. As you may remember there are two different definitions of a limit in metric spaces. They are 
	\begin{enumerate}
		\item Limits of sequences
		\item Limits of functions
	\end{enumerate}
	\medskip
	Below we give definitions for each of them. 
	
	\medskip
	
	\begin{definition}[Limit of a sequence]
		We say that the sequence $\{x_n\}_{n \in \mathbb{N}} \subseteq (X, d)$ converges to $x' \in X$ and write $$\lim_{n \to \infty} x_n = x'$$ if for any $\epsilon > 0$ there exists a  natural number $N > 0$ such that $d(x_n, x') < \epsilon$ for all $n > N$
	\end{definition}
	
	\medskip
	
	\begin{definition}[Limit of a function]
		Let $(X, d_X)$ and $(Y, d_Y)$ be metric spaces. Suppose that $E \subseteq X$. Let $f : E \to Y$ and suppose that $p$ is a limit point of $E$. We say that $$\lim_{x \to p} f(x) = q$$ if there exists a $q \in Y$ such that for all $\epsilon > 0$ there exists a $\delta > 0$ such that $$0 < d_X(x, p) < \delta \implies d_Y((f(x), q) < \epsilon$$ for any $x \in B_{(X, d_x)}(p, \delta)$
	\end{definition}
	
		\todog{1. Show that in $\mathbb{R}^n$ with the usual topology it simplies to $p \in \overline{E}$}
		\todog{2. Theorems about limits in $\R^n$ from Hubbard and Hubbard \cite{hubbard2006}}
		\todog{3. Limits and continuity theorems}
		\todog{4. Techniques to show limits exists and calculate limits}
		\todog{The whole of chapter 4 in Rudin is a treasure trove of theorems that would be useful here.}
		
	
	
	
	Now with the two notions of a limit defined we can define the derivative. This is quite an important point which warrants the need for this to have a bit of space so that the reader can see it and not forget it.
	\medskip
	\begin{remark}
		In the definition of the derivative the limit we will be using is the limit of a function!
	\end{remark}
	
	\subsection{Defining the Derivative}
	
	
	\begin{definition}[Derivative as defined in Munkres \cite{munkres2018analysis}]
		Let $A \subseteq \mathbb{R}$ and let $f : A \to \mathbb{R}$ be any function. Suppose that $A$ contains a neighborhood of the point $a$. We define the derivative of $f$ at $a$ by the equation $$f'(a) = \lim_{t \to 0} \frac{f(a+t) - f(a)}{t}$$ provided that the limit exists.
	\end{definition}
	
	But wait before we can go any further we \textbf{really need too} unpack this definition and see what's going on under the hood. The reader at this point is probably going \textit{"Hey author, urmm how exactly are we using the definition of the limit of a function here? Heck what is the function we're even taking a limit of here"} and your author will get to that in a second, just bear with me. \\
		
	Personally I would define the derivative in a much cleaner way (and I will do so later), but the above definition is basically the convention in mathematics as it's taught in high-school and first-year undergraduate courses and (hopefully) everybody is used to it. \\
		
	Understanding this definition will not only bridge the gap between high-school level mathematics and more advanced pure mathematics, but it will also give the reader an idea into the amount of mathematical maturity (e.g asking the simplest questions, which people sometimes say are silly questions) needed to truly understand concepts. Okay I'll shut up for now and proceed to unpack this definition. \\
	
	\textbf{Observation 1.}  The neighbourhood of $a$ that Munkres is referring to is an open set $U \subseteq A$  containing $a$ that is open in $\mathbb{R}$ as opposed to $U$ being open in the subspace $A$. But what would happen if we wanted the neighborhood of $a$ to be an open set of the subspace $A$ as opposed to $\mathbb{R}$? Well then we could have all kinds of wacky domains on which the function  we're taking the limit of (not to be confused with $f$ ) would be defined and the limit would not exist. We'll give some examples of this a bit later on below \\
	
	\textbf{Observation 2.} This is quite a subtle one. The fact that the definition above states that we need $A$ to contain a neighborhood of $a$ which, as we know by Observation $1.$, means that $A$ needs to contain a subset $U \subseteq A$ which contains $a$ and is also open in $\mathbb{R}$, but then this means that $a$ needs to be an interior point of $A$, since $U$ must be open in $\mathbb{R}$. So $a$ must be an interior point of $A$ for $f$ to even meet the criteria needed for $f$ to be differentiable at $a$. (So if $a\not\in \operatorname{Int}(A)$ then we don't even meet the criteria needed for $f$ to be differentiable at $a$, so $f$ can't be differentiable at $a$) Later on in my definition of the derivative I will just let $A$ be an open set and be done. \\
	
	This in essence shows that for a function to be differentiable on some domain, that domain must be particularly "nice", specifically we need the domain to be an open set in $\mathbb{R}$ and the only open sets in $\mathbb{R}$ are unions of open intervals and $\mathbb{R}$ and $\emptyset$. \\ 
		
	\textbf{Observation 3.} In the definition of $f'(a)$ no explicit mention of the domain function we're taking the limit of is given, we know that the function we're taking the limit of is $$\frac{f(a+t) - f(a)}{t}$$ but it is unclear over what domain this function is defined, and it's unclear if the criteria needed to take the limit of this function is satisfied. \\
	
	Since $A$ contains a neighborhood of $a$, which I'll call $U$ and since $U$ is open in $\mathbb{R}$, there exists an $r > 0$ such that $B(a, r) \subseteq U \subseteq A$.  Then note that $B(a, r) = (a-r, a+r)$. \\ \\ Now a \textbf{key} realization to make is that $\frac{f(a+t) - f(a)}{t}$ is defined for all $t \neq 0$ such that $a + t$ belongs to the neighborhood (which in this case becomes our open ball) of the point $a$. 
	The set of all such $t \in \mathbb{R}$ satisfying the properties given above is given by $$\{t \in \mathbb{R} \ | \  t\neq 0 \text{ and } a+t \in B(a, r) = (a-r, a+r)\} = B(0, r) \setminus \{0\}.$$ Thus we can define $\phi : B(0, r) \setminus \{0\} \to \mathbb{R}$ by $$\phi(t) = \frac{f(a+t) - f(a)}{t}$$ and then we can rewrite the derivative of $f$ as $$f'(a) = \lim_{t \to 0} \phi(t).$$ Furthermore note that $0 \in \mathbb{R}$ is a limit point of the set $B(0, r) \setminus \{0\}$ since any neighborhood of $0$ contains infinitely many members of $B(0, r) \setminus \{0\}$. Thus checking against our definition of a limit we see that all our criteria are satisfied so we can thus take the limit of $\phi$ as $t \to 0$\\
	
	\todog{Example of a function that is defined on an open set but which is not differentiable}
	
	\todog{4. Give an example of a function with a domain that's not nice and show why it isn't differentiable in two ways. Show that firstly that no point $a \in A$ has a nbhd in $\mathbb{R}$  which is  a subset of $A$ then go ahead anyway and show that the limit doesn't exist. Showing that the limit doesn't exist shows that the function won't be differentiable and why we must have the nbhd property as a priori for differentiability. This explains what G\&P meant when they said what they said in Differential Topology}


	Now below we'll get onto my definition of the derivative.
	
	\begin{definition}[My definition of the Derivative]
		Let $U \subseteq \mathbb{R}$ be an open set. Let $f : U \to \mathbb{R}$ be any function. Pick $a \in U$ and choose $r > 0$ such that $B(a, r) \subseteq U$. Define $\phi : B(0, r) \setminus \{0\} \to \mathbb{R}$ by $$\phi(t) = \frac{f(a+t) - f(a)}{t}.$$ Then we define the derivative of $f$ at $a$ as $$f'(a) = \lim_{t \to 0} \phi(t)$$ provided that the limit exists.
	\end{definition}
	
	One of the Professors I speak to online bugged me about even being able to talk  about the differentiability of $f : [0, 1] \to \mathbb{R}$ because $[0, 1]$ is not an open interval. My method for dealing with that would've been to restrict $f$ to it's interior and then analyse differentiability of the restricted function. (which I don't see anything wrong with) but some people might want a more general definition in which incorporate more general domains so they don't have to think about restrictions (but then again their functions on these general domains will only be differentiable on the interiors of those domains anyway *shrugs*)
	
	
	\begin{definition}[My more general definition of the Derivative]
		Let $A \subseteq \mathbb{R}$ and let $f : A \to \mathbb{R}$ be any function. Pick $a \in \operatorname{Int}(A)$ and choose $r > 0$ such that $B(a, r) \subseteq \operatorname{Int}(A)$. Define $\phi : B(0, r) \setminus \{0\} \to \mathbb{R}$ by $$\phi(t) = \frac{f(a+t) - f(a)}{t}.$$ Then we define the derivative of $f$ at $a$ as $$f'(a) = \lim_{t \to 0} \phi(t)$$ provided that the limit exists.
	\end{definition}
	
	\section{Integration in $\mathbb{R}^1$}
	
	For an \textbf{excellent} treatment of Riemann Integration in $\mathbb{R}^1$ using Darboux sums (which make computing the upper and lower integral sums easier) see \cite{math310notes}. We list a bevy of results that are extremely useful in using the Fundamental Theorem of Calculus rigorously.
	
	\begin{theorem}
		Let $f : [a, b] \to \mathbb{R}$. If $f \in C\left( [a, b]\right)$, then $f \in R\left( [a, b]\right)$. (In words if $f$ is continuous on $[a, b]$ then $f$ is Riemann integrable on $[a, b]$).
	\end{theorem}
	
	\todog{1. Fundamental Theorem of Calculus Part 1}
	\todog{2. Fundamental Theorem of Calculus Part 2}
	\todog{3. Measure theory results}
	
		\section{Differentiation in $\mathbb{R}^n$}
		
		\medskip
		
		\subsection{Prerequisites}
		
		
		\bigskip
		
		\begin{theorem}
			Let $(X, d)$ be a metric space and let $f_1, ..., f_k$ be real valued functions on $X$  (that is $f_i : X \to \mathbb{R}$ for $i \in \{1, \dots k\}$ ) and let $\mathbf{f} : X \to \mathbb{R}^k$ be defined by $$\mathbf{f}(x) = \left( f_1(x), \dots, f_k(x)\right)$$ then $\mathbf{f}$ is continuous if and only if each of the functions $f_1, \dots, f_k$ is continuous.  
		\end{theorem}
		
		\bigskip
		
		\begin{theorem}
			Let $(X, d)$ be a metric space and suppose that \\ $\mathbf{f}, \mathbf{g} : X \to \mathbb{R}^k$ are continuous functions, then $\mathbf{f} + \mathbf{g} : X \to \mathbb{R}^k$ defined by $$\left( \mathbf{f} + \mathbf{g}\right) (x) = \left( f_1(x) + g_1(x), \dots, f_k(x) + g_k(x)\right) $$ is continuous on $X$ and $\mathbf{f \cdot g} : X \to \mathbb{R}$ defined by $$\left( \mathbf{f \cdot g} \right)(x) =  \left( f_1(x) , \dots, f_k(x) \right)  \odot  \left( g_1(x), \dots,  g_k(x)\right) = f_1(x)\cdot g_1(x) + \dots f_k(x) \cdot g_k(x)$$ is continuous on $X$.
		\end{theorem}
		
		\medskip
		
		\begin{remark}
			Note that $\odot$ refers to the dot product on the vector space $\mathbb{R}^k$. The above theorem shows that addition of vector-valued functions whose domains are metric spaces (which could possibly be $\mathbb{R}^m$ for any $m \in \mathbb{N}$)  are continuous, and so is taking the dot product of vector valued functions. Proofs of the above theorems can be found in \cite{rudin1964principles}
		\end{remark}
	
	
	\bibliography{bibliography}{}
	\bibliographystyle{plain}
	

    
\end{document}